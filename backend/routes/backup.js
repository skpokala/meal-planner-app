const express = require('express');
const router = express.Router();
const { authenticateToken } = require('../middleware/auth');
const mongoose = require('mongoose');
const { body, validationResult } = require('express-validator');
const multer = require('multer');
const fs = require('fs').promises;
const path = require('path');
const { execSync } = require('child_process');

// Configure multer for file uploads
const storage = multer.memoryStorage();
const upload = multer({
  storage,
  limits: {
    fileSize: 50 * 1024 * 1024, // 50MB limit
  },
  fileFilter: (req, file, cb) => {
    const allowedTypes = ['.js', '.json'];
    const ext = path.extname(file.originalname).toLowerCase();
    if (allowedTypes.includes(ext)) {
      cb(null, true);
    } else {
      cb(new Error('Only .js and .json files are allowed'));
    }
  }
});

// Import all models for introspection
const User = require('../models/User');
const FamilyMember = require('../models/FamilyMember');
const Meal = require('../models/Meal');
const MealPlan = require('../models/MealPlan');
const Ingredient = require('../models/Ingredient');
const Store = require('../models/Store');
const Bug = require('../models/Bug');
const Audit = require('../models/Audit');

// Helper function to check if user is admin
const isAdmin = (user) => {
  return user.role === 'admin' || user.isSystemAdmin;
};

// Helper function to get current app version
const getCurrentVersion = () => {
  try {
    const packageJson = require('../../package.json');
    return packageJson.version;
  } catch (error) {
    return '1.0.0';
  }
};

// Helper function to get database statistics
const getDatabaseStats = async () => {
  const stats = {};
  const models = { User, FamilyMember, Meal, MealPlan, Ingredient, Store, Bug, Audit };
  
  for (const [modelName, Model] of Object.entries(models)) {
    try {
      const count = await Model.countDocuments();
      const sampleDoc = await Model.findOne().lean();
      stats[modelName] = {
        count,
        hasData: count > 0,
        schema: sampleDoc ? Object.keys(sampleDoc) : [],
        modelVersion: Model.schema.get('versionKey') || '__v'
      };
    } catch (error) {
      stats[modelName] = {
        count: 0,
        hasData: false,
        error: error.message,
        schema: []
      };
    }
  }
  
  return stats;
};

// Helper function to create pre-restore backup
const createPreRestoreBackup = async () => {
  try {
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
    const backupData = await generateJsonExport([]);
    const filename = `pre-restore-backup-${timestamp}.json`;
    
    // In a production environment, you might want to save this to a persistent location
    // For now, we'll return the backup data to be stored in memory or temporary location
    return {
      filename,
      data: backupData,
      timestamp: new Date().toISOString()
    };
  } catch (error) {
    throw new Error(`Failed to create pre-restore backup: ${error.message}`);
  }
};

// Helper function to validate script compatibility
const validateScriptCompatibility = (scriptContent, scriptType) => {
  const compatibility = {
    isValid: true,
    errors: [],
    warnings: [],
    metadata: null
  };

  try {
    if (scriptType === 'json') {
      const data = JSON.parse(scriptContent);
      
      // Validate JSON structure
      if (!data.metadata || !data.data) {
        compatibility.errors.push('Invalid JSON structure: missing metadata or data');
        compatibility.isValid = false;
        return compatibility;
      }
      
      compatibility.metadata = data.metadata;
      
      // Check version compatibility
      const scriptVersion = data.metadata.version;
      const currentVersion = getCurrentVersion();
      
      if (scriptVersion && scriptVersion !== currentVersion) {
        compatibility.warnings.push(`Script version ${scriptVersion} differs from current version ${currentVersion}`);
      }
      
      // Validate required fields
      if (!data.metadata.timestamp) {
        compatibility.warnings.push('Script metadata missing timestamp');
      }
      
      if (!data.metadata.type || data.metadata.type !== 'json_export') {
        compatibility.errors.push('Invalid or missing export type in metadata');
        compatibility.isValid = false;
      }
      
    } else if (scriptType === 'mongodb') {
      // Validate MongoDB script
      if (!scriptContent.includes('Generated backup script for Meal Planner App')) {
        compatibility.warnings.push('Script may not be generated by this application');
      }
      
      if (!scriptContent.includes('// Version:')) {
        compatibility.warnings.push('Script missing version information');
      }
      
      // Extract version from script comments
      const versionMatch = scriptContent.match(/\/\/ Version: ([\d.]+)/);
      if (versionMatch) {
        compatibility.metadata = { version: versionMatch[1] };
        const scriptVersion = versionMatch[1];
        const currentVersion = getCurrentVersion();
        
        if (scriptVersion !== currentVersion) {
          compatibility.warnings.push(`Script version ${scriptVersion} differs from current version ${currentVersion}`);
        }
      }
      
      // Check for potentially dangerous operations
      const dangerousPatterns = [
        /db\.dropDatabase\(\)/,
        /db\..*\.drop\(\)/,
        /db\..*\.remove\(\)/,
        /db\..*\.deleteMany\(\)/
      ];
      
      for (const pattern of dangerousPatterns) {
        if (pattern.test(scriptContent)) {
          compatibility.warnings.push('Script contains potentially destructive operations');
          break;
        }
      }
      
    } else {
      compatibility.errors.push('Unsupported script type');
      compatibility.isValid = false;
    }
    
  } catch (error) {
    compatibility.errors.push(`Script parsing error: ${error.message}`);
    compatibility.isValid = false;
  }
  
  return compatibility;
};

// Helper function to execute JSON import
const executeJsonImport = async (jsonData, options = {}) => {
  const results = {
    success: true,
    collections: {},
    totalImported: 0,
    errors: [],
    warnings: []
  };
  
  const models = { User, FamilyMember, Meal, MealPlan, Ingredient, Store, Bug, Audit };
  
  // Start a session for transaction
  const session = await mongoose.startSession();
  
  try {
    await session.withTransaction(async () => {
      for (const [collectionName, collectionData] of Object.entries(jsonData.data)) {
        if (!collectionData.records || !Array.isArray(collectionData.records)) {
          continue;
        }
        
        const Model = models[collectionName];
        if (!Model) {
          results.warnings.push(`Model ${collectionName} not found, skipping`);
          continue;
        }
        
        try {
          // Clear existing data if specified
          if (options.clearExisting) {
            await Model.deleteMany({}, { session });
          }
          
          // Import records
          if (collectionData.records.length > 0) {
            const imported = await Model.insertMany(collectionData.records, { 
              session,
              ordered: false // Continue on individual errors
            });
            
            results.collections[collectionName] = {
              imported: imported.length,
              total: collectionData.records.length
            };
            results.totalImported += imported.length;
          }
          
        } catch (error) {
          results.errors.push(`Error importing ${collectionName}: ${error.message}`);
          // Don't mark as failed for individual collection errors
        }
      }
    });
    
  } catch (error) {
    results.success = false;
    results.errors.push(`Transaction failed: ${error.message}`);
  } finally {
    await session.endSession();
  }
  
  return results;
};

// Helper function to generate MongoDB backup script
const generateMongoBackupScript = async (collections = [], includeIndexes = true) => {
  const stats = await getDatabaseStats();
  const version = getCurrentVersion();
  const timestamp = new Date().toISOString();
  const requiredMongoVersion = "4.0"; // Define the required MongoDB version
  
  let script = `// Generated backup script for Meal Planner App
// Version: ${version}
// Generated: ${timestamp}
// Compatible with: MongoDB 4.0+, Mongoose 6.0+

// Database connection check
if (!db) {
  print("Error: Not connected to database");
  quit(1);
}

// Version compatibility check
const appVersion = "${version}";
const requiredMongoVersion = "${requiredMongoVersion}";
const currentVersion = db.version();
print("Current MongoDB version: " + currentVersion);
print("Required MongoDB version: " + requiredMongoVersion);

// Database statistics at time of backup
const backupStats = ${JSON.stringify(stats, null, 2)};
print("Backup statistics:");
printjson(backupStats);

`;

  // Generate backup commands for each collection
  const collectionsToBackup = collections.length > 0 ? collections : Object.keys(stats);
  
  for (const collectionName of collectionsToBackup) {
    const modelName = collectionName.toLowerCase();
    const Model = {
      user: User,
      familymember: FamilyMember, 
      meal: Meal,
      mealplan: MealPlan,
      ingredient: Ingredient,
      store: Store,
      bug: Bug,
      audit: Audit
    }[modelName];
    
    if (!Model || !stats[collectionName] || !stats[collectionName].hasData) {
      script += `// Skipping ${collectionName} - no data or model not found\n\n`;
      continue;
    }
    
    script += `// ========== ${collectionName} Collection ==========\n`;
    script += `print("Processing ${collectionName} collection...");\n`;
    script += `const ${modelName}Count = db.${modelName}s.countDocuments();\n`;
    script += `print("Found " + ${modelName}Count + " documents in ${collectionName}");\n\n`;
    
    // Generate data export
    script += `// Export ${collectionName} data\n`;
    script += `const ${modelName}Data = db.${modelName}s.find({}).toArray();\n`;
    script += `print("Exporting " + ${modelName}Data.length + " ${collectionName} records...");\n\n`;
    
    // Generate indexes if requested
    if (includeIndexes) {
      script += `// Export ${collectionName} indexes\n`;
      script += `const ${modelName}Indexes = db.${modelName}s.getIndexes();\n`;
      script += `print("Found " + ${modelName}Indexes.length + " indexes for ${collectionName}");\n\n`;
    }
  }
  
  // Add restoration instructions
  script += `
// ========== RESTORATION INSTRUCTIONS ==========
/*
To restore this backup:

1. Ensure MongoDB is running and accessible
2. Connect to your target database: mongo <database_name>
3. Run this script: load("backup_script.js")

OR

For individual collections:
- db.<collection>.insertMany(<collection>Data);
- db.<collection>.createIndexes(<collection>Indexes);

IMPORTANT NOTES:
- This script preserves ObjectIds and timestamps
- Ensure target database is empty or use dropDatabase() first
- Verify all dependencies and references are maintained
- Test in a development environment first

Version compatibility:
- Generated for app version: ${version}
- Requires MongoDB ${requiredMongoVersion}+
- Compatible with Mongoose 6.0+
*/

print("Backup script generation completed successfully");
print("Total collections processed: ${collectionsToBackup.length}");
print("Generated at: ${timestamp}");
`;

  return script;
};

// Helper function to generate JSON export
const generateJsonExport = async (collections = []) => {
  const stats = await getDatabaseStats();
  const version = getCurrentVersion();
  const timestamp = new Date().toISOString();
  
  const exportData = {
    metadata: {
      version,
      timestamp,
      type: 'json_export',
      compatibility: {
        minAppVersion: '1.0.0',
        mongoVersion: '4.0+',
        nodeVersion: '16.0+'
      },
      statistics: stats
    },
    data: {}
  };
  
  const collectionsToExport = collections.length > 0 ? collections : Object.keys(stats);
  
  for (const collectionName of collectionsToExport) {
    const modelName = collectionName.toLowerCase();
    const Model = {
      user: User,
      familymember: FamilyMember,
      meal: Meal, 
      mealplan: MealPlan,
      ingredient: Ingredient,
      store: Store,
      bug: Bug,
      audit: Audit
    }[modelName];
    
    if (!Model || !stats[collectionName] || !stats[collectionName].hasData) {
      exportData.data[collectionName] = { count: 0, records: [] };
      continue;
    }
    
    try {
      const records = await Model.find({}).lean();
      exportData.data[collectionName] = {
        count: records.length,
        records: records,
        indexes: Model.collection.getIndexes ? await Model.collection.getIndexes() : []
      };
    } catch (error) {
      exportData.data[collectionName] = {
        count: 0,
        records: [],
        error: error.message
      };
    }
  }
  
  return exportData;
};

// Helper function to execute MongoDB script in container
const executeMongoScript = async (scriptContent, options = {}) => {
  const results = {
    success: true,
    output: [],
    errors: [],
    warnings: []
  };

  try {
    // Create temporary script file
    const tempDir = '/tmp';
    const scriptId = Date.now() + '_' + Math.random().toString(36).substr(2, 9);
    const tempScriptPath = path.join(tempDir, `backup_script_${scriptId}.js`);
    
    // Write script to temporary file
    await fs.writeFile(tempScriptPath, scriptContent);
    
    // Execute script in MongoDB container using mongosh
    const containerName = 'meal-planner-mongo';
    const dbName = process.env.MONGODB_URI ? 
      process.env.MONGODB_URI.split('/').pop().split('?')[0] : 
      'meal_planner';
    
    // Copy script to container
    const containerScriptPath = `/tmp/backup_script_${scriptId}.js`;
    execSync(`docker cp "${tempScriptPath}" "${containerName}:${containerScriptPath}"`);
    
    // Execute script in container
    const command = `docker-compose exec -T mongo mongosh ${dbName} --eval "load('${containerScriptPath}')" --quiet`;
    
    try {
      const output = execSync(command, { 
        encoding: 'utf8',
        timeout: 300000, // 5 minute timeout
        maxBuffer: 10 * 1024 * 1024 // 10MB buffer
      });
      
      results.output.push(output);
      
      // Check for common error patterns in output
      if (output.includes('Error:') || output.includes('error:')) {
        results.warnings.push('Script execution completed but may contain errors - check output carefully');
      }
      
    } catch (execError) {
      results.success = false;
      results.errors.push(`Script execution failed: ${execError.message}`);
      if (execError.stdout) results.output.push(execError.stdout);
      if (execError.stderr) results.errors.push(execError.stderr);
    }
    
    // Cleanup: Remove temporary files
    try {
      await fs.unlink(tempScriptPath);
      execSync(`docker-compose exec -T mongo rm -f "${containerScriptPath}"`);
    } catch (cleanupError) {
      results.warnings.push('Temporary file cleanup failed - files may remain in /tmp');
    }
    
  } catch (error) {
    results.success = false;
    results.errors.push(`Failed to execute MongoDB script: ${error.message}`);
  }
  
  return results;
};

// POST /api/backup/generate-script
// Generate backup script
router.post('/generate-script', [
  authenticateToken,
  body('format').isIn(['mongodb', 'json']).withMessage('Format must be mongodb or json'),
  body('collections').optional().isArray().withMessage('Collections must be an array'),
  body('includeIndexes').optional().isBoolean().withMessage('Include indexes must be boolean'),
  body('includeData').optional().isBoolean().withMessage('Include data must be boolean')
], async (req, res) => {
  try {
    const errors = validationResult(req);
    if (!errors.isEmpty()) {
      return res.status(400).json({
        success: false,
        message: 'Validation failed',
        errors: errors.array()
      });
    }

    const user = req.user;
    if (!isAdmin(user)) {
      return res.status(403).json({
        success: false,
        message: 'Admin access required'
      });
    }

    const { format = 'mongodb', collections = [], includeIndexes = true, includeData = true } = req.body;
    
    // Log the backup request
    console.log(`Backup script requested by ${user.email || user.name} for format: ${format}`);
    
    let result;
    let filename;
    let contentType;
    
    if (format === 'mongodb') {
      result = await generateMongoBackupScript(collections, includeIndexes);
      filename = `meal-planner-backup-${new Date().toISOString().split('T')[0]}.js`;
      contentType = 'application/javascript';
    } else if (format === 'json') {
      result = await generateJsonExport(collections);
      filename = `meal-planner-export-${new Date().toISOString().split('T')[0]}.json`;
      contentType = 'application/json';
      result = JSON.stringify(result, null, 2);
    }
    
    // Set headers for file download
    res.setHeader('Content-Type', contentType);
    res.setHeader('Content-Disposition', `attachment; filename="${filename}"`);
    
    res.status(200).send(result);
    
  } catch (error) {
    console.error('Error generating backup script:', error);
    res.status(500).json({
      success: false,
      message: 'Failed to generate backup script',
      error: process.env.NODE_ENV === 'development' ? error.message : undefined
    });
  }
});

// POST /api/backup/validate-script
// Validate uploaded script for compatibility
router.post('/validate-script', [
  authenticateToken,
  upload.single('script')
], async (req, res) => {
  try {
    const user = req.user;
    if (!isAdmin(user)) {
      return res.status(403).json({
        success: false,
        message: 'Admin access required'
      });
    }

    if (!req.file) {
      return res.status(400).json({
        success: false,
        message: 'No script file uploaded'
      });
    }

    const scriptContent = req.file.buffer.toString('utf8');
    const scriptType = path.extname(req.file.originalname).toLowerCase() === '.json' ? 'json' : 'mongodb';
    
    const validation = validateScriptCompatibility(scriptContent, scriptType);
    
    res.status(200).json({
      success: true,
      data: {
        filename: req.file.originalname,
        size: req.file.size,
        type: scriptType,
        validation,
        uploadedAt: new Date().toISOString()
      }
    });
    
  } catch (error) {
    console.error('Error validating script:', error);
    res.status(500).json({
      success: false,
      message: 'Failed to validate script',
      error: process.env.NODE_ENV === 'development' ? error.message : undefined
    });
  }
});

// POST /api/backup/import-script
// Execute uploaded script to restore data
router.post('/import-script', [
  authenticateToken,
  upload.single('script'),
  body('options.clearExisting').optional().isBoolean().withMessage('Clear existing must be boolean'),
  body('options.createBackup').optional().isBoolean().withMessage('Create backup must be boolean'),
  body('options.allowMongoExecution').optional().isBoolean().withMessage('Allow mongo execution must be boolean'),
  body('confirmed').isBoolean().withMessage('Confirmation is required')
], async (req, res) => {
  try {
    const errors = validationResult(req);
    if (!errors.isEmpty()) {
      return res.status(400).json({
        success: false,
        message: 'Validation failed',
        errors: errors.array()
      });
    }

    const user = req.user;
    if (!isAdmin(user)) {
      return res.status(403).json({
        success: false,
        message: 'Admin access required'
      });
    }

    if (!req.body.confirmed) {
      return res.status(400).json({
        success: false,
        message: 'Import must be explicitly confirmed'
      });
    }

    if (!req.file) {
      return res.status(400).json({
        success: false,
        message: 'No script file uploaded'
      });
    }

    const scriptContent = req.file.buffer.toString('utf8');
    const scriptType = path.extname(req.file.originalname).toLowerCase() === '.json' ? 'json' : 'mongodb';
    const options = req.body.options || {};
    
    // Validate script first
    const validation = validateScriptCompatibility(scriptContent, scriptType);
    if (!validation.isValid) {
      return res.status(400).json({
        success: false,
        message: 'Script validation failed',
        errors: validation.errors
      });
    }

    // Create pre-restore backup if requested
    let preRestoreBackup = null;
    if (options.createBackup !== false) { // Default to true
      try {
        preRestoreBackup = await createPreRestoreBackup();
      } catch (error) {
        return res.status(500).json({
          success: false,
          message: 'Failed to create pre-restore backup',
          error: error.message
        });
      }
    }

    // Execute import based on script type
    let importResults;
    
    if (scriptType === 'json') {
      const jsonData = JSON.parse(scriptContent);
      importResults = await executeJsonImport(jsonData, options);
    } else {
      // MongoDB script execution
      if (options.allowMongoExecution === true) {
        // Execute MongoDB script in controlled environment
        importResults = await executeMongoScript(scriptContent, options);
        importResults.type = 'mongodb_script';
        importResults.notice = 'MongoDB script executed in container environment';
      } else {
        // Return instructions for manual execution (existing behavior)
        return res.status(200).json({
          success: false,
          message: 'MongoDB script requires explicit execution permission',
          info: 'MongoDB scripts can be executed automatically or manually',
          automaticExecution: {
            enabled: false,
            instructions: 'Check "Allow automatic MongoDB script execution" in import options to enable',
            warning: 'Automatic execution runs scripts in the MongoDB container environment'
          },
          manualExecution: {
            instructions: [
              '1. Copy script to MongoDB container: docker cp script.js meal-planner-mongo:/tmp/',
              '2. Connect to MongoDB: docker-compose exec mongo mongosh meal_planner',
              '3. Execute script: load("/tmp/script.js")',
              '4. Monitor output for errors and completion status'
            ]
          },
          validation,
          preRestoreBackup: preRestoreBackup ? {
            filename: preRestoreBackup.filename,
            timestamp: preRestoreBackup.timestamp
          } : null
        });
      }
    }

    // Log the import operation
    console.log(`Data import completed by ${user.email || user.name}:`, {
      filename: req.file.originalname,
      type: scriptType,
      totalImported: importResults.totalImported || 'N/A',
      success: importResults.success
    });

    res.status(200).json({
      success: importResults.success,
      data: {
        filename: req.file.originalname,
        type: scriptType,
        importResults,
        preRestoreBackup: preRestoreBackup ? {
          filename: preRestoreBackup.filename,
          timestamp: preRestoreBackup.timestamp
        } : null,
        validation,
        executedAt: new Date().toISOString(),
        executedBy: user.email || user.name
      }
    });
    
  } catch (error) {
    console.error('Error importing script:', error);
    res.status(500).json({
      success: false,
      message: 'Failed to import script',
      error: process.env.NODE_ENV === 'development' ? error.message : undefined
    });
  }
});

// GET /api/backup/database-info
// Get database information and statistics
router.get('/database-info', authenticateToken, async (req, res) => {
  try {
    const user = req.user;
    if (!isAdmin(user)) {
      return res.status(403).json({
        success: false,
        message: 'Admin access required'
      });
    }

    const stats = await getDatabaseStats();
    const version = getCurrentVersion();
    
    // Get MongoDB version and connection info
    const mongoInfo = {
      version: mongoose.version,
      connectionState: mongoose.connection.readyState,
      host: mongoose.connection.host,
      port: mongoose.connection.port,
      name: mongoose.connection.name
    };
    
    res.status(200).json({
      success: true,
      data: {
        appVersion: version,
        timestamp: new Date().toISOString(),
        mongodb: mongoInfo,
        collections: stats,
        totalDocuments: Object.values(stats).reduce((sum, stat) => sum + (stat.count || 0), 0),
        availableFormats: ['mongodb', 'json']
      }
    });
    
  } catch (error) {
    console.error('Error getting database info:', error);
    res.status(500).json({
      success: false,
      message: 'Failed to retrieve database information',
      error: process.env.NODE_ENV === 'development' ? error.message : undefined
    });
  }
});

// POST /api/backup/validate-compatibility
// Validate backup compatibility with current environment
router.post('/validate-compatibility', [
  authenticateToken,
  body('backupVersion').notEmpty().withMessage('Backup version is required'),
  body('backupData').optional().isObject().withMessage('Backup data must be an object')
], async (req, res) => {
  try {
    const errors = validationResult(req);
    if (!errors.isEmpty()) {
      return res.status(400).json({
        success: false,
        message: 'Validation failed',
        errors: errors.array()
      });
    }

    const user = req.user;
    if (!isAdmin(user)) {
      return res.status(403).json({
        success: false,
        message: 'Admin access required'
      });
    }

    const { backupVersion, backupData } = req.body;
    const currentVersion = getCurrentVersion();
    const currentStats = await getDatabaseStats();
    
    const compatibility = {
      isCompatible: true,
      warnings: [],
      errors: [],
      recommendations: []
    };
    
    // Version compatibility check
    const backupVersionNum = parseFloat(backupVersion.replace(/[^\d.]/g, ''));
    const currentVersionNum = parseFloat(currentVersion.replace(/[^\d.]/g, ''));
    
    if (backupVersionNum > currentVersionNum) {
      compatibility.errors.push(`Backup version ${backupVersion} is newer than current app version ${currentVersion}`);
      compatibility.isCompatible = false;
    }
    
    if (backupVersionNum < 1.0) {
      compatibility.warnings.push('Backup from pre-1.0 version may have compatibility issues');
    }
    
    // Schema compatibility check
    if (backupData && backupData.metadata && backupData.metadata.statistics) {
      const backupStats = backupData.metadata.statistics;
      
      for (const [collection, backupStat] of Object.entries(backupStats)) {
        const currentStat = currentStats[collection];
        
        if (!currentStat) {
          compatibility.warnings.push(`Collection ${collection} from backup not found in current schema`);
          continue;
        }
        
        // Check for missing fields
        if (backupStat.schema && currentStat.schema) {
          const missingFields = backupStat.schema.filter(field => !currentStat.schema.includes(field));
          if (missingFields.length > 0) {
            compatibility.warnings.push(`Collection ${collection} backup contains fields not in current schema: ${missingFields.join(', ')}`);
          }
        }
      }
    }
    
    // Add recommendations
    if (compatibility.warnings.length > 0) {
      compatibility.recommendations.push('Test restoration in a development environment first');
    }
    
    if (compatibility.errors.length === 0 && compatibility.warnings.length === 0) {
      compatibility.recommendations.push('Backup appears fully compatible with current environment');
    }
    
    res.status(200).json({
      success: true,
      data: {
        compatibility,
        currentVersion,
        backupVersion,
        currentEnvironment: {
          mongodb: mongoose.version,
          node: process.version,
          collections: Object.keys(currentStats)
        }
      }
    });
    
  } catch (error) {
    console.error('Error validating compatibility:', error);
    res.status(500).json({
      success: false,
      message: 'Failed to validate compatibility',
      error: process.env.NODE_ENV === 'development' ? error.message : undefined
    });
  }
});

module.exports = router; 